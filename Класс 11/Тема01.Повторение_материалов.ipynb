{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Тема01.Повторение_материалов.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JeyeN7NlD_d-"},"source":["# Тема 01. Введение в нейронные сети\n","\n","Мы начинаем изучение удивительного мира нейронных сетей, познакомимся с методами решения большого количества задач, напишем стихи, нарисуем картину, создадим музыку. \n","\n","Поговорим о возможностях и опасностях нейронных сетей.\n","\n","Познакомимся с другими технологиями, которые, часто применяются вместе с нейронными сетями.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-EFuU6HXlLpp"},"source":["# План занятий 11 класса\n","Вот полный план наших занятий:\n","\n","### 1 полугодие 11 класса:\n","* 01. Повторение основных понятий нейронных сетей из 10 класса, многослойный персептрон, сверточные сети.\n","Повтор основных положений нейронных сетей. Слоистые сети, полносвязные и не полносвязные, сверточные сети. Обучающее, проверочное, тестовое множество. Градиентный спуск. Обратное распространение ошибки. И др. \n","* 02. Виды и параметры сверток.\n","Углубленное изучение сверток. Двумерные свертки. Реализация в Tensorflow (Keras): принятые соглашения при работе со свертками, тензоры. Понятие ядра (kernel) свертки и размера ядра; понятие фильтра, количество фильтров в слое; понятие сдвига (stride), его параметры; понятие набивки (padding), ее параметры; понятие групп (groups) и их параметры. Распределенная (dilated) свертка, аргумент dilation_rate. Транспонированная (transposed) свертка, ее аргументы. Разделимые (separable) свертки, идея, реализация и сравнение. Контрольные задания.\n","* 03. Методы оптимизации.\n","Краткое напоминание метода градиентного спуска. Проблемы градиентного спуска. Модификации градиентного спуска. Метод знака градиента. Моменты. Стохастический градиентный спуск с [первым] моментом. Автоматическая регулировка шага обучения, RMSProp. Метод Adam. Сравнение методов на простом примере (распознавание типа одежды). Идеи других методов оптимизации: моменты Нестерова, методы второго порядка.\n","* 04. Способы повышения обобщающей способности: dropout, нормализация и регуляризация.\n","Явления недообучения и переобучения, борьба с ними. Регуляризация параметров, L1 и L2 регуляризация, о разреженности параметров при L1 регуляризации. Добавление случайности, метод dropout. Нормализация, пакетная нормализация batchNormalization. Использование изучаемых методов на примере полносвязных сетей определения элементарных частиц (Higgs dataset); работа с объектом Dataset. Контрольные задания. Домашняя работа.\n","* 05. Аугментация данных\n","Понятие аугментации данных. Объект ImageDataGenerator для аугментации изображений. Реализация аугментаций: повороты, сдвиги, масштабирование, отражение и др. Пример классификации кошек и собак с и без аугментации. Создание собственного генератора данных. О других аугментациях.  \n","* 06. Перенос обучения. Векторные представления изображений\n","О сложностях обучения нейронных сетей. Идея переноса обучения (transfer learning). Пример использования предобученной сети VGG для набора данных CalTech-101 и сравнение с обучением с нуля. Векторные представления изображений, библиотека Img2Vec. TSNE проекция векторов изображений. Сравнение изображений по их векторам, поиск похожих и не похожих (по косинусному расстоянию). Задания. \n","\n","* 07. Детекция\\локализация объектов на изображении.\n","Задачи классификации, локализации, детекции и сегментации объектов на изображении. Идеи и архитектура сети YOLO. Оценка похожести ограничивающих окон, метрика «пересечения над объединением» IoU. Пример детекции сетью YOLOv4 из библиотеки Darknet. Пример детекции объектов в видео. Задания. \n","* 08. Попиксельная классификация (сегментация)\n","Понятие маски изображения. Идеи и архитектуры сетей типа R-CNN (R-CNN, Fast-R-CNN, Faster-R-CNN), Mask-RCNN. Пример работы Mask-RCNN для изображения. Пример работы Mask-RCNN для изображения с веб-камеры. Задания. \n","* 09. Состязательные атаки на нейронные сети классификации изображений\n","Обман нейронной сети, состязательные атаки (adversarial attack), идея. Направленные и не направленные атаки. Атака методом быстрого знака градиента. Пример в библиотеке CleverHans. Обсуждение других атак, физических атак, проблем и способов защиты. Задания.\n","* 10. Генеративно – состязательный подход, теория\n","Генеративно – состязательный подход. Сети дискриминатора и генератора их задачи. Общий вид генеративно-состязательной сети (Generative-Adversarial Network, GAN), латентные входы. Пример генерации синусоид, проблемы самостоятельного обучения GAN, предобучение дискриминатора и генератора. Задания.\n","* 11. Генерация изображений\n","Использование обученных генераторов изображений. Идеи и архитектура сети StyleGAN2. Пример генерации изображений рыбок. Изучения влияния латентных переменных на генерацию изображений лиц, морфинг. Задания.\n","* 12. Перенос стиля изображения\n","Задача переноса стиля изображения. Расчет ошибок стиля и содержания. Представление стиля – матрица Грамма. Генерация изображения с контролем ошибок стиля и содержания. Реализация процедуры генерации в Keras, использование автодифференцирования. Задания.\n","* 13. Изменение изображений\n","Пример задачи изменения изображения – создание мультяшного изображения. Идея и архитектура сети CartoonGAN, ошибка генерации и содержания. Пример. Задания.\n","* 14. Сверточные сети для обработки речи\n","О представлении звуков. Одномерные свертки. Задача распознавания речи. Ошибка CTC (Connectionist Temporal Classification): понятие символа «промежуток», поиск подходящих последовательностей, расчет ошибки. О модификациях ошибки CTC. Сверточная сеть Wav2letter для распознавания речи. Пример распознавания речи сетью Wav2Letter+. Задания.\n","\n","* 15. Реализация итогового проекта.\n","Распознаем заболевания томатов по изображению их листьев – поможем аграриям!\n","Варианты: \n","а) индивидуальный – каждый обучающийся выполняет проект самостоятельно, заполняя пропуски в прездаполненном файле-задании. Учитель проверяет правильность.\n","б) групповой – группы обучающихся соревнуются между собой за достижение лучшего результата, изменяя параметры методов, представленные в файле-решении. Оценка по занятому месту.\n","* 16. Презентация результатов итогового проекта\n","Обучающиеся презентуют свои решения, сравнивают с предложенным в файле-решении.\n","\n","### 2 полугодие 11 класса:\n","* 17. Рекуррентные нейронные сети\n","Добавление времени в нейронную сеть. Нейронные сети с временными задержками. Рекуррентные сети, понятие обратной связи. Рекуррентный нейрон, проблема обучения. Разворачивание рекуррентных сетей во времени. Примеры рекуррентных сетей, нейронная сеть NARX (Nonlinear AutoRegression with eXternal input). Архитектурные ограничения NARX, обучение NARX по разомкнутому циклу. Библиотека Sysidentpy, пример моделирования процесса. Задания.\n","* 18. Вентильные сети. LSTM, GRU\n","Проблема долгосрочных зависимостей. Понятие вентиля (gate). Устройство LSTM-нейрона (Long Short Term Memory) и LSTM-сети. Устройство GRU (Gated Recurrent Unit) нейрона. О создании других вентильных сетей. Пример прогноза температуры с помощью вентильной нейронной сети. Задания.\n","* 19. Генерация музыки вентильными сетями\n","Формат MIDI для представления музыки. Архитектура LSTM генератора музыки. Пример генерации музыки.\n","* 20. Векторные представления слов.\n","Векторные представления слов. Унитарный код (one-hot). Контекст слов, идея и архитектура Word2vec представления. Геометрия слов. Косинусное расстояние. Библиотека gensim: сравнение слов, поиск похожих слов и др. Работа с моделями для русского языка. Векторные представления слов GloVe (Global Vectors), примеры. Векторные представления FastText, использование n-грамм символов, примеры. Задания. \n","* 21. Механизм внимания. Сети Transformer, BERT\n","Проблемы учета влияния слов друг на друга. Двунаправленный LSTM. Механизм внимания (attention). Множественное (multihead) внимание. Идея и архитектура сети Transformer, различия работы в процессе обучения и генерации. Идея и архитектура сети BERT: предсказание маски, предсказание следующей последовательности. Пример работы BERT (DistilBERT) для классификации отзывов на фильм. \n","* 22. Векторные представления речи Wav2Vec. Клонирование голоса.\n","BERT-подобная сеть Wav2Vec для векторного представления речи: квантование, маскирование, функции ошибки, самообучение и обучение с учителем. Пример распознавания речи. Пример клонирования голоса с библиотекой CorentinJ/Real-Time-Voice-Cloning. \n","* 23. Генерация текста. Пишем стихи.\n","Генеративные сети для обработки текста. Проблемы стихосложения. Идеи и архитектуры сетей для генерации стихов. Пример. Задания.\n","* 24. Аннотирование изображений\n","Совместные векторные представления изображений и текста. Задача аннотирования изображений. Примеры сетей для аннотации изображений. Об обратной задаче – генерации изображения по аннотации, пример.\n","\n","* 25. Эволюционные и генетические вычисления «Почему вымерли динозавры»\n","Понятие эволюционных вычислений. Метод «роя частиц»: устройство, пример в библиотеке PySwarms. Генетические алгоритмы: генетический код, функция приспособленности, процедуры отбора, скрещивания, мутации. Онлайн-пример «генетических машинок». Пример решения задачи о рюкзаке с библиотекой pyeasyga. Задания.\n","* 26. Нечеткие числа и системы. «Ну примерно половинка»\n","Понятие нечетких множеств и нечеткой логики (fuzzy logic). Функция принадлежности. Нечеткие логические операции: объединение (ИЛИ), пересечение (И), дополнение (НЕ). Пример нечеткого логического вывода, библиотека skfuzzy. Задания. Нейро-нечеткая сеть ANFIS, пример прогноза временного ряда. \n","* 27. Нейрокриптография. «Играем в шпионов»\n","Понятия криптографии. Генерация секретных ключей, протокол Диффи-Хеллмана. Архитектура древовидных машин четности (tree parity machines). Генерация секретного ключа с помощью древовидных машин четности. Методы обновления весов. Реализация протокола генерации секретного ключа. Имитация злоумышленника. Исследование влияния параметров на процесс синхронизации. Задания.\n","* 28. Чат-боты «Поговори со мной»\n","Задача построения чат-бота, виды чат-ботов. Подходы к построению чат-ботов. Пример самостоятельной реализации чат-бота.\n","* 29. Обучение с подкреплением «Не мешает подкрепиться»\n","Понятие обучения с подкреплением (reinforcement learning). Q-обучение, идея и формулы. Эпсилон-жадный выбор. Пример управления тележкой (библиотека gym) с Q-обучением. Задания. Онлайн-пример. \n","* 30. Подходы к работе с большими данными «Ох, как много данных»\n","Понятие больших данных. Вычислительные проблемы больших данных. Подход map-reduce. Самостоятельная реализация подхода. Другие примеры. Задания.\n","* 31. Реализация итогового проекта.\n","Игра угадывания слова по ассоциациям. \n","Варианты: \n","а) индивидуальный – каждый обучающийся выполняет проект самостоятельно, заполняя пропуски в прездаполненном файле-задании. Учитель проверяет правильность.\n","б) групповой – группы обучающихся соревнуются между собой за достижение лучшего результата, изменяя параметры методов, представленные в файле-решении. Оценка по занятому месту.\n","* 32. Презентация результатов итогового проекта\n","Обучающиеся презентуют свои решения, сравнивают с предложенным в файле-решении.\n"]},{"cell_type":"markdown","metadata":{"id":"7C60xLw5mwwc"},"source":["# Важные темы из 10 класса.\n","Прежде чем приступать к изучению нового материала повторите и освежите знания по материалам 10 класса, особенно:\n","\n","* [Тема 12](https://colab.research.google.com/drive/11Ve6aV-FDEstSLljIZ8CmFlhBgoETVgy ) Задачи машинного обучения, понятие модели, обучения\n","*  [Тема 13](https://colab.research.google.com/drive/10BqGqfVJHy-eUDFJl0EOjXPFRl6bN8vx ) Линейная и логистическая регрессия (особенно часть про градиентный спуск)\n","* [Тема 21](https://colab.research.google.com/drive/1i-O70iYNyeLOKh-jXPFEpM_ljjI2086o)\n","Ансамбли. Бустинг, раздел о кроссвалидации. \n","* [Тема 27](https://colab.research.google.com/drive/1F_l3eryntlM0SAq2Ep_yaxnzsTUuIea-) Нейронные сети, глубокое обучение. Фреймворки\n","* [Тема 28](https://colab.research.google.com/drive/1eeM14hC3Ls2tmS5YBD4VApVkTk4K0rfr) Нейрон и нейронная сеть. И самое пристальное внимание обратите на раздел о методе обратного распространения ошибки.\n","* [Тема 30](https://colab.research.google.com/drive/1Efl9fpUnOx5gZYzlC_leA7eqAkjqHTtD) {[часть 2](https://colab.research.google.com/drive/1ZYVsrMo_vdVlkME2YfdeY5Bowq8PhEOo )}  Сверточные нейронные сети.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"JOike-oclLEO"},"source":[""],"execution_count":null,"outputs":[]}]}