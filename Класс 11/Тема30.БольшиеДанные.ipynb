{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Тема30.БольшиеДанные.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aq_ZPTl9VhLO"},"source":["# Тема 30. Работа с большими данными."]},{"cell_type":"markdown","metadata":{"id":"SEP8zN0FVy-5"},"source":["# Распараллеливание операций\n","Количество данных, которые надо обрабатывать, растет изо дня в день. В моем детстве получить в [подарок компьютер](https://www.computer-museum.ru/articles/personalnye-evm/899/) с 40 *мегабайтами* ($40*10^6$ байт) дисковой памяти было просто потрясающе. Сегодня никого уже не удивить [хранилищами](https://www.ixbt.com/news/2017/12/08/toshiba-mg07aca-14.html) на полтора десятка *терабайт* ($15*10^{12}$ байт).   "]},{"cell_type":"markdown","metadata":{"id":"I-Fh5EbvbQL_"},"source":["Но объемы данных растут гораздо быстрее, чем емкость дисков и памяти для их хранения и обработки. Например, количество данных, собранных [Большим Адронным Коллайдером](https://www.lhc-closer.es/taking_a_closer_look_at_lhc/0.lhc_data_analysis) уже перевалило за 200 *петабайт* ($200*10^{15}$ байт), добавляя по 10-15 петабайт каждый год. \n","\n","При таких объемах данных привычная нам обработка - когда мы загружаем все данные в память компьютера и запускаем программу -  не работает. Такие данные, когда традиционные подходы к их обработке не работают из-за большого количества этих данных, назвали [**Большими Данными**](https://ru.wikipedia.org/wiki/Большие_данные) (Big Data).\n","\n","*Большие данные* это не очень точно определенное понятие, нельзя назвать конкретную цифру, когда данные считать большими, а когда нет. Главный признак больших данных - они не помещаются в одну физическую память.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6gfRIxHigcEU"},"source":["Как же работать с большими данными?\n","\n","Раз не можем хранить и обрабатывать такие данные на одном устройстве - будем делать это на нескольких, **распараллелим вычисления**! "]},{"cell_type":"markdown","metadata":{"id":"7ydAZiK5hlSW"},"source":["Представьте такой пример: надо сложить восемь чисел (a, b, c, d, e, f, g, h), используя несколько вычислителей одновременно. Как это можно сделать? \n","\n","Операция сложения *коммутативна и ассоциативна*.\n","* Коммутативна - мы можем менять порядок слагаемых и сумма не изменится.\n","* Ассоциативна -  можем объединить слагаемые в группы, сложить их внутри групп, а потом сложить результаты каждой группы и опять сумма не изменится (т.е. можно расставлять скобочки по своему усмотрению).\n","\n","Пусть у нас есть два вычислителя, тогда можем поступить так:\n","* первый вычислитель - принимает числа abcd и складывает их.\n","* второй вычислитель в то же самое время принимает числа efgh и складывает их.\n","* какой-то, например, первый, вычислитель принимает результаты от первого и второго и складывает их.\n","\n","А если вычислителей четыре? \n","\n","Такое можно посчитать за несколько шагов  (см. рис.).\n","\n","Шаг 1:\n","* первый вычислитель принимает два числа a и b и складывает их.\n","* одновременно второй принимает c и d, складывает их.\n","* одновременно с ними третий вычислитель принимает e и f, складывает.\n","* и, наконец, четвертый вычислитель одновременно принимает g и h, складывает.\n","\n","Шаг 2:\n","* первый вычислитель принимает результат с шага 1 от себя и второго вычислителя, складывает эти результаты.\n","* второй вычислитель простаивает, ничего не делает.\n","* третий вычислитель принимает результат с шага 1 от себя и четвертого вычислителя, складывает эти результаты.\n","* четвертый простаивает, ничего не делает.\n","\n","Шаг 3:\n","* первый вычислитель принимает результат с шага 2 от себя и третьего вычислителя, складывает эти результаты.\n","* второй, третий и четвертый вычислители простаивают, ничего не делают.\n","\n","\n","![img](http://www.cburch.com/books/distalg/sum.png)\n","\n","\n","После третьего шага в первом вычислителе получился искомый результат - сумма всех чисел. Ровно по тому же принципу можно работать, когда чисел триллионы и есть несколько вычислителей.\n","\n","Обратите внимание, что вычислители работают одновременно друг с другом, в то же самое время и весь алгоритм занимает только три шага. Можно придумать и другие схемы работы вычислителей, например, принимать не по два, а по четыре числа. В любом случае мы имеем некоторую схему распараллеливания вычислений, в которой можем регулировать количество данных обрабатываемых каждым вычислителем. В нашем примере каждый вычислитель принимал только два числа. Давайте всегда делать так, чтобы это количество помещалось в память вычислителя.\n","\n","Важное наблюдение - каждый вычислитель работает со своей порцией данных, значит можно изначально записать и хранить их так, чтобы порции попадали в память своего вычислителя - нам не нужно одно большое хранилище данных.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"dBZQZY3jnWPm"},"source":["Раз подход работает со сложением - будет работать и с другими ассоциативными операциями, например, поиск самого длинного слова в большом тексте. Действительно, это ассоциативная операция: если слово А длиннее слова Б, а слово В длиннее слова Г, разбив их на группы на первом шаге выделим слова А и В и сравнив их, найдем на втором шаге наиболее длинное. Результат будет таким же, если бы мы сравнивали слова постепенно.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AVH5n5DjIX23"},"source":["Здесь нам надо сначала найти для слов их длину, а уже потом объединять результаты от разных вычислителей. При объединении же результатов, мы теперь используем не сумму, а выбор максимума.\n","\n","И другие похожие задачи можно решать аналогичным способом, который назвали **Map-Reduce**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_sCvXabmJHGh"},"source":["# Map-Reduce\n","В подходе Map-Reduce вычисления разбиваются логически на три этапа:\n","- **Map**, отображение - предварительная обработка входных данных в виде большого списка значений. При этом главный узел (логический вычислитель) кластера (master node) получает этот список, делит его на части и передает рабочим узлам (worker node). Далее каждый рабочий узел применяет заданную функцию Map (например, подсчет количества слов в предложении) к локальным данным и записывает результат в формате «ключ-значение» во временное хранилище. Здесь же может выполняться фильтрация данных, например, отбросить не подходящие. \n","- **Shuffle**, распределение -  когда рабочие узлы перераспределяют данные на основе ключей, ранее созданных функцией Map, таким образом, чтобы все данные одного ключа лежали на одном рабочем узле.\n","- **Reduce**, свертка – параллельная обработка каждым рабочим узлом каждой группы данных по порядку следования ключей и «склейка» результатов на master node. \n","\n","Главный узел получает промежуточные ответы от рабочих узлов и передаёт их на свободные узлы для выполнения следующего этапа. Получившийся после прохождения всех необходимых этапов результат – это и есть решение исходной задачи.\n","\n","![img](https://www.bigdataschool.ru/wp-content/uploads/2019/10/MapReduce3.png)\n","\n","На рисунке выше показан пример, где для каждого слова в тексте подсчитывается сколько раз оно встретилось. \n","\n","Весь текст разбивается на 4 части, каждая поступает на свой узел, где применяется отображение map - подсчет числа вхождений слов в эту часть. Слова это ключи, их число вхождений - значения.\n","\n","Для каждого ключа-слова создается свой логический узел, куда поступает информация из блоков map, на каждый узел попадает свое слово. Это именно логические узлы, физически они могут располагаться на одном или нескольких вычислителях.\n","\n","В каждом узле применяется агрегирующая функция reduce, здесь - подсчет количества записей, это и коммутативная и ассоциативная операция.\n","\n","Затем результаты собираются на главном узле, где мы и получили окончательный ответ - число вхождений слов во всем тексте.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UOEcr6CGpHGR"},"source":["## 1. Простая реализация Map-Reduce. \n","\n","Сделаем свою простую реализацию подхода Map-Reduce для поиска наиболее длинного слова в тексте.\n","\n","*Примечание: в наших простых примерах все помещается в память, но подход работает и для более сложных случаев* "]},{"cell_type":"markdown","metadata":{"id":"QzbPBqX1qDT3"},"source":["Сделаем функцию для поиска наиболее длинной строки в списке. Перебираем строки по очереди, вычисляем длину и сохраняем самую длинную строку, пока не закончим.\n"]},{"cell_type":"code","metadata":{"id":"WYVpdGuWpdWI","executionInfo":{"status":"ok","timestamp":1628958151054,"user_tz":-180,"elapsed":16,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["# Функция для поиска наиболее длинной строки в списке строк\n","def find_longest_string(list_of_strings): # принимаем список строк\n","    longest_string = None\n","    longest_string_len = 0 \n","    for s in list_of_strings: # берем каждую строку из списка\n","        if len(s) > longest_string_len: # находим ее длину\n","            longest_string_len = len(s) # если больше чем предыдущие, то запоминаем длину\n","            longest_string = s # и саму строку\n","    return longest_string"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"toZMBgbWqBnH"},"source":["Для небольших списков это работает довольно быстро. \n","\n","3 строки:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BfLbtvzqA2i","executionInfo":{"status":"ok","timestamp":1628958153937,"user_tz":-180,"elapsed":404,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"950e2150-884b-40d1-bf91-79e915a5d710"},"source":["list_of_strings = ['abc', 'python', 'dima']\n","%time max_length = print(find_longest_string(list_of_strings))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["python\n","CPU times: user 629 µs, sys: 0 ns, total: 629 µs\n","Wall time: 636 µs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3WJUyU_2qdjY"},"source":["3000 строк:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQZbYJONqcts","executionInfo":{"status":"ok","timestamp":1628958156430,"user_tz":-180,"elapsed":8,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"5fcead1f-fd0c-4f31-acaa-d714eea57e60"},"source":["large_list_of_strings = list_of_strings*1000\n","%time print(find_longest_string(large_list_of_strings))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["python\n","CPU times: user 2.38 ms, sys: 95 µs, total: 2.48 ms\n","Wall time: 6.35 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_-l1FuGWqpji"},"source":["300 миллионов строк, уже долго:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUPGWLm5quSd","executionInfo":{"status":"ok","timestamp":1628958187895,"user_tz":-180,"elapsed":27227,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"48ea1fe6-99e4-4ad4-b58f-5b8e25f278aa"},"source":["large_list_of_strings = list_of_strings*100000000\n","%time print(find_longest_string(large_list_of_strings))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["python\n","CPU times: user 26.8 s, sys: 41.8 ms, total: 26.8 s\n","Wall time: 26.8 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xS4-a579UHoy"},"source":["Используемая функция для этапа map здесь это подсчет длины слова, просто функция len. Чтобы применять такую функцию к данным воспользуемся встроенной функцией map().\n","\n","Используемая функция для этапа reduce здесь это выбор максимального значения (ищем наиболее длинное слово). Встроенной функции reduce нет, воспользуемся такой функцией из библиотеки [`functools`](https://pythonworld.ru/moduli/modul-functools.html). В ней используемая функция должна принимать два агрегируемых аргумента ключ-значение.\n","\n","Этап распределения shuffle здесь не нужен, так как результат хранится в одном массиве. "]},{"cell_type":"code","metadata":{"id":"pt1MCusurteb","executionInfo":{"status":"ok","timestamp":1628958197028,"user_tz":-180,"elapsed":424,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["# Используемые функции\n","mapper = len # подсчет длины слова\n","def reducer(p, c): # выбор максимального элемента\n","    if p[1] > c[1]: # каждый аргумент это пара ключ-значение, значения имеют индекс 1.\n","        return p\n","    return c"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcaODSnNsVCH","executionInfo":{"status":"ok","timestamp":1628958199860,"user_tz":-180,"elapsed":381,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["from functools import reduce"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kXQyRikrvpn","executionInfo":{"status":"ok","timestamp":1628958201418,"user_tz":-180,"elapsed":9,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"e798729d-842f-410b-c4ed-b67911ad9c74"},"source":["%%time\n","# этап 1\n","mapped = map(mapper, list_of_strings) # применяем функцию расчета длины к каждому слову\n","mapped = zip(list_of_strings, mapped) # и делаем пары ключ-значение, ключ - слово, значение - длина \n","# этап 2:\n","reduced = reduce(reducer, mapped) # агрегируем поиском максимума\n","print(reduced)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["('python', 6)\n","CPU times: user 187 µs, sys: 10 µs, total: 197 µs\n","Wall time: 148 µs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_78XuuQVZYxX"},"source":["Выше мы работали сразу со всеми данными, но обычно данные разделяются на части. Сделаем и для такого примера."]},{"cell_type":"markdown","metadata":{"id":"QSGF1Sb-Zn28"},"source":["Разделим данные на части:"]},{"cell_type":"code","metadata":{"id":"UX97jv2EuaMT","executionInfo":{"status":"ok","timestamp":1628958208358,"user_tz":-180,"elapsed":397,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["# разделение данных на заданное число частей\n","def chunkify(seq, number_of_chunks=30):\n","  return (seq[i::number_of_chunks] for i in range(number_of_chunks))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3MuaYeQGZ21s"},"source":["Для каждой части выполняем функции map-reduce. Но так как теперь частей несколько, то результаты для каждой части также нужно объединить. У нас это та же самая операция reduce (выбираем общий максимум из максимумов частей).\n","\n","Операции map-reduce для одной части данных определим в виде функции: "]},{"cell_type":"code","metadata":{"id":"9ilMge3mx0hs","executionInfo":{"status":"ok","timestamp":1628958212124,"user_tz":-180,"elapsed":380,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["# map-reduce для одной части данных\n","def chunks_mapper(chunk):\n","    mapped_chunk = map(mapper, chunk)  # применяем функцию расчета длины к каждому слову\n","    mapped_chunk = zip(chunk, mapped_chunk) # и делаем пары ключ-значение\n","    return reduce(reducer, mapped_chunk) # агрегируем поиском максимум\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OiIKvIJkax3P"},"source":["Применим."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gojOYuJx63b","executionInfo":{"status":"ok","timestamp":1628958290306,"user_tz":-180,"elapsed":75708,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"c8e83c6e-7512-4c3e-bbc7-70dc8b80df17"},"source":["%%time\n","# разделяем на части\n","data_chunks = chunkify(large_list_of_strings, number_of_chunks=30)\n","# ко всем частям применяем map-reduce\n","mapped = map(chunks_mapper, data_chunks)\n","# объединяем результаты от всех частей\n","reduced = reduce(reducer, mapped)\n","print(reduced)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["('python', 6)\n","CPU times: user 1min 15s, sys: 300 ms, total: 1min 16s\n","Wall time: 1min 15s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5jltepfzbR4j"},"source":["Если бы у нас было много процессоров, то с помощью библиотеки multiprocessing можно было бы распараллелить эти вычисления. Но в Colab выделен только один процессор, поэтому никакого прироста скорости не будет. Но если у вас есть компьютер с несколькими процессорами, то вы увидите прирост скорости выполнения. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOhTTbkLyTdw","executionInfo":{"status":"ok","timestamp":1628958373126,"user_tz":-180,"elapsed":80639,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"d90f1edf-1257-49c8-aa2b-dcd132d04c62"},"source":["%%time\n","from multiprocessing import Pool\n","pool = Pool(8) # создаем \"кластер\" из восьми процессоров\n","data_chunks = chunkify(large_list_of_strings, number_of_chunks=8) # разделяем данные на 8 частей\n","# ко всем частям применяем map-reduce, но теперь каждая часть считается на своем процессоре\n","mapped = pool.map(chunks_mapper, data_chunks)\n","# объединяем результаты от всех частей\n","reduced = reduce(reducer, mapped)\n","print(reduced)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["('python', 6)\n","CPU times: user 15 s, sys: 2.04 s, total: 17 s\n","Wall time: 1min 20s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sq8U3BtmhtRx"},"source":["## 2. Pyspark\n","\n","Подход Map-Reduce реализован в нескольких системах: [Hadoop]( https://ru.wikipedia.org/wiki/Hadoop), [Spark]( https://ru.wikipedia.org/wiki/Apache_Spark) и др.\n","\n","Мы посмотрим на работу [Pyspark](https://spark.apache.org/docs/latest/api/python/) для языка Python.\n","\n","Здесь работа с данными в подходе Map-Reduce реализована прозрачно для пользователя, система сама будет создавать необходимые узлы, и выполнять необходимые этапы.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1VUJI_psoVEt"},"source":["### Установка\n","Прежде нужно установить в Colab все необходимые средства, а именно Apache Spark подходящей версии с hadoop 2.7, Java 8. Также Findspark, которая поможет настроить Spark. Ниже нужно указать подходящую версию, сейчас это 2.4.8:"]},{"cell_type":"code","metadata":{"id":"lh5NCoc8fsSO","executionInfo":{"status":"ok","timestamp":1628958597203,"user_tz":-180,"elapsed":52977,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["# Устанавливаем Java\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# скачиваем Spark\n","!wget -q https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\n","# распаковываем\n","!tar xf spark-2.4.8-bin-hadoop2.7.tgz\n","# устанавливаем findspark\n","!pip install -q findspark"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ILheUROOhprv"},"source":["Для работы необходимо прописать пути к Java и Spark в системную переменную среды."]},{"cell_type":"code","metadata":{"id":"v1b8k_OVf2QF","executionInfo":{"status":"ok","timestamp":1628958667440,"user_tz":-180,"elapsed":385,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" # путь к Java\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\" # путь к Spark (укажите вашу версию)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KwrqMk3HiMiE"},"source":["Инициализируем и проверим работу локальной сессии spark:"]},{"cell_type":"code","metadata":{"id":"9_Uz1NL4gHFx","executionInfo":{"status":"ok","timestamp":1628958773807,"user_tz":-180,"elapsed":9586,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["import findspark\n","findspark.init() # настраивает pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate() # создаем сессию"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEb4HTRwiaJx"},"source":["### Вычисление линейной регрессии\n","\n","В Pyspark реализовано множество вычислительных методов, есть и методы машинного обучения. Например, линейная регрессия.\n","\n","Скачаем данные о домах в Бостоне [отсюда](https://github.com/asifahmed90/pyspark-ML-in-Colab/blob/master/BostonHousing.csv)."]},{"cell_type":"code","metadata":{"id":"u32AG8zzDHj6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958964219,"user_tz":-180,"elapsed":928,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"ad6dd79e-72d6-4eb8-fb54-8ed9f08266c1"},"source":["!wget https://raw.githubusercontent.com/asifahmed90/pyspark-ML-in-Colab/master/BostonHousing.csv"],"execution_count":15,"outputs":[{"output_type":"stream","text":["--2021-08-14 16:36:18--  https://raw.githubusercontent.com/asifahmed90/pyspark-ML-in-Colab/master/BostonHousing.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 35735 (35K) [text/plain]\n","Saving to: ‘BostonHousing.csv’\n","\n","BostonHousing.csv   100%[===================>]  34.90K  --.-KB/s    in 0.004s  \n","\n","2021-08-14 16:36:19 (8.65 MB/s) - ‘BostonHousing.csv’ saved [35735/35735]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m606eNuQgA82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628958994537,"user_tz":-180,"elapsed":397,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"2980b663-ffde-4071-fc8a-8d2778c6a8ac"},"source":["!ls # проверим папку"],"execution_count":16,"outputs":[{"output_type":"stream","text":["BostonHousing.csv  spark-2.4.8-bin-hadoop2.7\n","sample_data\t   spark-2.4.8-bin-hadoop2.7.tgz\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"21D9EANUvnwF"},"source":["Для работы нам потребуется два модуля из Pyspark: VectorAssembler и LinearRegression. VectorAssembler собирает все признаки типа double из нескольких столбцов в один. Если в данных есть строковые признаки, то следует использовать  StringIndexer, но в наших данных этого нет.  \n","\n","Методом spark.read.csv() читаем данные из файла, указываем, что названия столбцов надо взять из файла и в нем есть заголовок."]},{"cell_type":"code","metadata":{"id":"0ZeJ7WQCgM8g","executionInfo":{"status":"ok","timestamp":1628959198896,"user_tz":-180,"elapsed":6107,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}}},"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import LinearRegression\n","\n","dataset = spark.read.csv('BostonHousing.csv',inferSchema=True, header =True)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJLoAfqVv8-E"},"source":["Создается объект DataFrame spark, который по смыслу очень похож на pandas DataFrame, но реализован на spark. \n","\n","Посмотрим схему данных - информацию о столбцах."]},{"cell_type":"code","metadata":{"id":"Gok1FXWugYkE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959457192,"user_tz":-180,"elapsed":409,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"c8a6ba02-98ae-4642-e785-776b77cc4cb9"},"source":["dataset.printSchema()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["root\n"," |-- crim: double (nullable = true)\n"," |-- zn: double (nullable = true)\n"," |-- indus: double (nullable = true)\n"," |-- chas: integer (nullable = true)\n"," |-- nox: double (nullable = true)\n"," |-- rm: double (nullable = true)\n"," |-- age: double (nullable = true)\n"," |-- dis: double (nullable = true)\n"," |-- rad: integer (nullable = true)\n"," |-- tax: integer (nullable = true)\n"," |-- ptratio: double (nullable = true)\n"," |-- b: double (nullable = true)\n"," |-- lstat: double (nullable = true)\n"," |-- medv: double (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3L9VJqsHwEGf"},"source":["Собираем все признаки из разных столбцов в один столбец 'Attributes' в переменной outputCol, кроме \"medv\", который будет целевым значением. "]},{"cell_type":"code","metadata":{"id":"sKSqdT9QgkfD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628959533649,"user_tz":-180,"elapsed":937,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"cfcf97fd-df8f-4ee1-88f8-beb60db35b06"},"source":["# Собираем все признаки из разных столбцов в один столбец\n","# задаем сборщик\n","assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')\n","# применяем сборщик\n","output = assembler.transform(dataset)\n","\n","# таблица входов и целевых значений\n","finalized_data = output.select(\"Attributes\",\"medv\")\n","# напечатаем\n","finalized_data.show()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["+--------------------+----+\n","|          Attributes|medv|\n","+--------------------+----+\n","|[0.00632,18.0,2.3...|24.0|\n","|[0.02731,0.0,7.07...|21.6|\n","|[0.02729,0.0,7.07...|34.7|\n","|[0.03237,0.0,2.18...|33.4|\n","|[0.06905,0.0,2.18...|36.2|\n","|[0.02985,0.0,2.18...|28.7|\n","|[0.08829,12.5,7.8...|22.9|\n","|[0.14455,12.5,7.8...|27.1|\n","|[0.21124,12.5,7.8...|16.5|\n","|[0.17004,12.5,7.8...|18.9|\n","|[0.22489,12.5,7.8...|15.0|\n","|[0.11747,12.5,7.8...|18.9|\n","|[0.09378,12.5,7.8...|21.7|\n","|[0.62976,0.0,8.14...|20.4|\n","|[0.63796,0.0,8.14...|18.2|\n","|[0.62739,0.0,8.14...|19.9|\n","|[1.05393,0.0,8.14...|23.1|\n","|[0.7842,0.0,8.14,...|17.5|\n","|[0.80271,0.0,8.14...|20.2|\n","|[0.7258,0.0,8.14,...|18.2|\n","+--------------------+----+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dNgFCto2wHLd"},"source":["Разделяем данные на обучающее и тестовое множества (0.8 и 0.2).\n","\n","Задаем регрессор, обучаем его, проверяем как обучилось. Синтаксис очень похож на sklearn."]},{"cell_type":"code","metadata":{"id":"kwe1VT0UNOIN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628960213407,"user_tz":-180,"elapsed":3742,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"0ae218c9-2fab-42cd-c5fc-062fd8009ce6"},"source":["# Разделяем данные на обучающее и тестовое множества\n","train_data,test_data = finalized_data.randomSplit([0.8,0.2])\n","\n","# Задаем регрессор\n","regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n","\n","# обучаем его\n","regressor = regressor.fit(train_data)\n","\n","# проверяем как обучилось\n","pred = regressor.evaluate(test_data)\n","\n","# печатаем результат\n","pred.predictions.show()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["+--------------------+----+------------------+\n","|          Attributes|medv|        prediction|\n","+--------------------+----+------------------+\n","|[0.0136,75.0,4.0,...|18.9| 15.35710411524662|\n","|[0.02899,40.0,1.2...|26.6| 21.92403439567257|\n","|[0.03041,0.0,5.19...|18.5|19.558399887571934|\n","|[0.03237,0.0,2.18...|33.4| 28.62371762785608|\n","|[0.03466,35.0,6.0...|19.4| 23.02527470807725|\n","|[0.03738,0.0,5.19...|20.7|21.574017965979316|\n","|[0.04741,0.0,11.9...|11.9|22.638194555590267|\n","|[0.05059,0.0,4.49...|23.9|24.842508436836994|\n","|[0.05083,0.0,5.19...|22.2|22.152484706038727|\n","|[0.05497,0.0,5.19...|19.0|  21.3987125603013|\n","|[0.05644,40.0,6.4...|32.4| 37.07794830806628|\n","|[0.06211,40.0,1.2...|22.9|20.348580485157004|\n","|[0.06417,0.0,5.96...|18.9| 24.06867640324641|\n","|[0.06588,0.0,2.46...|39.8| 35.18985767958472|\n","|[0.06905,0.0,2.18...|36.2| 28.04773781775772|\n","|[0.06911,45.0,3.4...|30.5|29.889488988907367|\n","|[0.07165,0.0,25.6...|20.3|23.053793272197208|\n","|[0.0795,60.0,1.69...|24.1|20.255568043598714|\n","|[0.07978,40.0,6.4...|29.1|30.459644169523337|\n","|[0.08873,21.0,5.6...|19.7|21.389325288293833|\n","+--------------------+----+------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y3vYyp5dwOm_"},"source":["Можно напечатать полученные коэффициенты линейной регрессии и смещение:"]},{"cell_type":"code","metadata":{"id":"Eja1BLiaTThT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628960222351,"user_tz":-180,"elapsed":583,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"72cafd9b-90ee-474b-943a-c023fc8684ec"},"source":["# коэффициенты\n","coeff = regressor.coefficients\n","\n","# смещение\n","intr = regressor.intercept\n","\n","print (\"The coefficient of the model is : %a\" %coeff)\n","print (\"The Intercept of the model is : %f\" %intr)\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["The coefficient of the model is : DenseVector([-0.1086, 0.0517, 0.0261, 3.5586, -19.1003, 3.7844, 0.0106, -1.5005, 0.3368, -0.0149, -0.9116, 0.0098, -0.5219])\n","The Intercept of the model is : 36.453686\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bYORz3Q9wTSW"},"source":["### Анализ\n","\n","Имея обученную регрессию можно считать различные статистики с помощью модуля RegressionEvaluator из Pyspark."]},{"cell_type":"code","metadata":{"id":"8qrQdEj62ptt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628960231303,"user_tz":-180,"elapsed":1287,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"3a4fff1a-f1a0-46cc-ebcb-d669642a78ee"},"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# создаем подсчитыватель статистики\n","eval = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n","\n","# считаем Root Mean Square Error\n","rmse = eval.evaluate(pred.predictions)\n","print(\"RMSE: %.3f\" % rmse)\n","\n","# считаем Mean Square Error\n","mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n","print(\"MSE: %.3f\" % mse)\n","\n","# считаем Mean Absolute Error\n","mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n","print(\"MAE: %.3f\" % mae)\n","\n","# считаем r2 - coefficient of determination\n","r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n","print(\"r2: %.3f\" %r2)\n","\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["RMSE: 4.688\n","MSE: 21.977\n","MAE: 3.643\n","r2: 0.623\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ViJK-LmLmqZH"},"source":["# Задания и вопросы\n","* Какая была функция map в примере со сложением чисел? (Никакая, числа брались как есть, без преобразований).\n","* Приведите примеры не коммутативных и\\или не ассоциативных операций. (например, вычитание, возведение в степень).\n","* Измените п.1 на поиск самого короткого слова\n","* Изучите документацию на [MLlib pyspark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html) и примените другой тип регрессии - на основе деревьев (DecisionTreeRegressor)."]},{"cell_type":"markdown","metadata":{"id":"jxg6CW4OzrrH"},"source":["# Ссылки\n","Использованы и адаптированы материалы:\n","* https://github.com/asifahmed90/pyspark-ML-in-Colab \n","* https://www.bigdataschool.ru/wiki/mapreduce \n","* https://colab.research.google.com/github/RPI-DATA/course-intro-ml-app/blob/master/content/notebooks/18-big-data/01-intro-mapreduce.ipynb \n","\n","Большое количество примеров машинного обучения с pyspark можно найти здесь:\n","* https://github.com/apache/spark/tree/v3.1.2-rc1/examples/src/main/python/mllib\n"]},{"cell_type":"code","metadata":{"id":"lPvohdURteY-"},"source":[""],"execution_count":null,"outputs":[]}]}